{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "### 1) import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from time import time\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Checkpoint Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model, checkpoint_dir):\n",
    "    print(\" [*] Reading checkpoints...\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt :\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
    "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
    "        counter = int(ckpt_name.split('-')[1])\n",
    "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "        return True, counter\n",
    "    else:\n",
    "        print(\" [*] Failed to find a checkpoint\")\n",
    "        return False, 0\n",
    "\n",
    "def check_folder(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    return dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Data load & pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist() :\n",
    "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "    train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
    "    test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
    "\n",
    "    train_data, test_data = normalize(train_data, test_data)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10]\n",
    "    test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def normalize(train_data, test_data):\n",
    "    train_data = train_data.astype(np.float32) / 255.0\n",
    "    test_data = test_data.astype(np.float32) / 255.0\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Performance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True) # trainig을 True로 하면 Dropout 사용\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
    "                                                                   from_logits=True))\n",
    "    return loss\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training=False) # trainig을 False로 하면 Dropout 사용 X\n",
    "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.trainable_variables) # model.variables 대신 써야 한다. \n",
    "    # batch norm 사용 시 처음에 gradient가 존재하지 않기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Model Function\n",
    "- Batch Normalization Function도 정의해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten() :\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init) :\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu() :\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
    "\n",
    "def dropout(rate):\n",
    "    return tf.keras.layers.Dropout(rate)\n",
    "\n",
    "def batch_norm():\n",
    "    return tf.keras.layers.BatchNormalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Create Model(function version)\n",
    "- dropout 함수 호출(Activation Function 다음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_function(label_dim) :\n",
    "    weight_init = tf.keras.initializers.he_uniform()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(flatten())\n",
    "\n",
    "    for i in range(4) :\n",
    "        model.add(dense(512, weight_init))\n",
    "        model.add(batch_norm()) # Activation Function 전에 쓴다.\n",
    "        # 보통은 FC/Conv Layer - Norm - Activation 순으로 쓰거나\n",
    "        # Norm - Activation - FC/Conv Layer 순으로 쓴다.\n",
    "        model.add(relu())\n",
    "        model.add(dropout(rate=0.5))\n",
    "\n",
    "    model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Define data & hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "train_x, train_y, test_x, test_y = load_mnist()\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "training_epochs = 1\n",
    "training_iterations = len(train_x) // batch_size\n",
    "\n",
    "label_dim = 10\n",
    "\n",
    "train_flag = True\n",
    "\n",
    "# Graph Input using Dataset API\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=len(test_x)).\\\n",
    "    batch(len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Define Model & Optimizer & Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "network = create_model_function(label_dim)\n",
    "\n",
    "# Training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Writer\n",
    "checkpoint_dir = 'checkpoints'\n",
    "logs_dir = 'logs'\n",
    "\n",
    "model_dir = 'nn_batch_norm'\n",
    "\n",
    "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "check_folder(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
    "logs_dir = os.path.join(logs_dir, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Restore checkpoint & start train or test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 0] [    0/  468] time: 2.0200, train_loss: 3.08599997, train_accuracy: 0.1328, test_Accuracy: 0.1368\n",
      "Epoch: [ 0] [    1/  468] time: 2.9670, train_loss: 2.95940471, train_accuracy: 0.1719, test_Accuracy: 0.1788\n",
      "Epoch: [ 0] [    2/  468] time: 3.9100, train_loss: 2.95802641, train_accuracy: 0.2734, test_Accuracy: 0.2293\n",
      "Epoch: [ 0] [    3/  468] time: 4.8510, train_loss: 2.73642445, train_accuracy: 0.3125, test_Accuracy: 0.2651\n",
      "Epoch: [ 0] [    4/  468] time: 5.7960, train_loss: 2.88379860, train_accuracy: 0.3516, test_Accuracy: 0.2747\n",
      "Epoch: [ 0] [    5/  468] time: 6.7580, train_loss: 2.84264708, train_accuracy: 0.3125, test_Accuracy: 0.2749\n",
      "Epoch: [ 0] [    6/  468] time: 7.6810, train_loss: 2.38648462, train_accuracy: 0.2734, test_Accuracy: 0.2733\n",
      "Epoch: [ 0] [    7/  468] time: 8.7290, train_loss: 2.64200544, train_accuracy: 0.2656, test_Accuracy: 0.2786\n",
      "Epoch: [ 0] [    8/  468] time: 9.7530, train_loss: 2.23606086, train_accuracy: 0.2891, test_Accuracy: 0.2881\n",
      "Epoch: [ 0] [    9/  468] time: 10.8230, train_loss: 2.54326916, train_accuracy: 0.2812, test_Accuracy: 0.2969\n",
      "Epoch: [ 0] [   10/  468] time: 11.8260, train_loss: 2.21288061, train_accuracy: 0.3203, test_Accuracy: 0.3047\n",
      "Epoch: [ 0] [   11/  468] time: 12.8160, train_loss: 2.29384851, train_accuracy: 0.3125, test_Accuracy: 0.3169\n",
      "Epoch: [ 0] [   12/  468] time: 13.7720, train_loss: 2.28685856, train_accuracy: 0.3281, test_Accuracy: 0.3367\n",
      "Epoch: [ 0] [   13/  468] time: 14.8060, train_loss: 2.16500044, train_accuracy: 0.3438, test_Accuracy: 0.3612\n",
      "Epoch: [ 0] [   14/  468] time: 15.8730, train_loss: 2.14444923, train_accuracy: 0.4766, test_Accuracy: 0.3877\n",
      "Epoch: [ 0] [   15/  468] time: 16.8100, train_loss: 2.09414339, train_accuracy: 0.3984, test_Accuracy: 0.4170\n",
      "Epoch: [ 0] [   16/  468] time: 17.7380, train_loss: 2.08516598, train_accuracy: 0.4688, test_Accuracy: 0.4400\n",
      "Epoch: [ 0] [   17/  468] time: 18.6680, train_loss: 1.87750912, train_accuracy: 0.3906, test_Accuracy: 0.4714\n",
      "Epoch: [ 0] [   18/  468] time: 19.5940, train_loss: 1.92688394, train_accuracy: 0.4375, test_Accuracy: 0.5010\n",
      "Epoch: [ 0] [   19/  468] time: 20.5110, train_loss: 1.95442796, train_accuracy: 0.5391, test_Accuracy: 0.5321\n",
      "Epoch: [ 0] [   20/  468] time: 21.4460, train_loss: 1.69394827, train_accuracy: 0.5000, test_Accuracy: 0.5617\n",
      "Epoch: [ 0] [   21/  468] time: 22.3610, train_loss: 1.72381866, train_accuracy: 0.5625, test_Accuracy: 0.5889\n",
      "Epoch: [ 0] [   22/  468] time: 23.3560, train_loss: 1.74022675, train_accuracy: 0.6641, test_Accuracy: 0.6125\n",
      "Epoch: [ 0] [   23/  468] time: 24.5000, train_loss: 1.83425796, train_accuracy: 0.6172, test_Accuracy: 0.6327\n",
      "Epoch: [ 0] [   24/  468] time: 25.5920, train_loss: 1.78742647, train_accuracy: 0.6172, test_Accuracy: 0.6483\n",
      "Epoch: [ 0] [   25/  468] time: 26.6100, train_loss: 1.64838290, train_accuracy: 0.6328, test_Accuracy: 0.6661\n",
      "Epoch: [ 0] [   26/  468] time: 27.7440, train_loss: 1.61560285, train_accuracy: 0.7109, test_Accuracy: 0.6788\n",
      "Epoch: [ 0] [   27/  468] time: 28.8910, train_loss: 1.63126016, train_accuracy: 0.7969, test_Accuracy: 0.6946\n",
      "Epoch: [ 0] [   28/  468] time: 29.8700, train_loss: 1.87388909, train_accuracy: 0.6250, test_Accuracy: 0.7073\n",
      "Epoch: [ 0] [   29/  468] time: 30.8200, train_loss: 1.39568996, train_accuracy: 0.6953, test_Accuracy: 0.7191\n",
      "Epoch: [ 0] [   30/  468] time: 31.9470, train_loss: 1.40157461, train_accuracy: 0.7344, test_Accuracy: 0.7276\n",
      "Epoch: [ 0] [   31/  468] time: 32.8920, train_loss: 1.30722094, train_accuracy: 0.7109, test_Accuracy: 0.7347\n",
      "Epoch: [ 0] [   32/  468] time: 33.8130, train_loss: 1.48121285, train_accuracy: 0.7578, test_Accuracy: 0.7415\n",
      "Epoch: [ 0] [   33/  468] time: 34.7400, train_loss: 1.15383744, train_accuracy: 0.7422, test_Accuracy: 0.7489\n",
      "Epoch: [ 0] [   34/  468] time: 35.6610, train_loss: 1.35079479, train_accuracy: 0.7344, test_Accuracy: 0.7557\n",
      "Epoch: [ 0] [   35/  468] time: 36.5780, train_loss: 1.47812307, train_accuracy: 0.7188, test_Accuracy: 0.7620\n",
      "Epoch: [ 0] [   36/  468] time: 37.9500, train_loss: 1.43038273, train_accuracy: 0.7656, test_Accuracy: 0.7673\n",
      "Epoch: [ 0] [   37/  468] time: 39.1110, train_loss: 1.18163705, train_accuracy: 0.7188, test_Accuracy: 0.7704\n",
      "Epoch: [ 0] [   38/  468] time: 40.4310, train_loss: 1.12588525, train_accuracy: 0.8047, test_Accuracy: 0.7735\n",
      "Epoch: [ 0] [   39/  468] time: 41.9820, train_loss: 1.14416385, train_accuracy: 0.7500, test_Accuracy: 0.7769\n",
      "Epoch: [ 0] [   40/  468] time: 43.4010, train_loss: 1.19771588, train_accuracy: 0.7734, test_Accuracy: 0.7795\n",
      "Epoch: [ 0] [   41/  468] time: 45.0430, train_loss: 1.20734382, train_accuracy: 0.7500, test_Accuracy: 0.7816\n",
      "Epoch: [ 0] [   42/  468] time: 47.1670, train_loss: 1.23343444, train_accuracy: 0.7500, test_Accuracy: 0.7835\n",
      "Epoch: [ 0] [   43/  468] time: 48.7740, train_loss: 1.28220057, train_accuracy: 0.8047, test_Accuracy: 0.7848\n",
      "Epoch: [ 0] [   44/  468] time: 50.0320, train_loss: 1.12899065, train_accuracy: 0.7656, test_Accuracy: 0.7858\n",
      "Epoch: [ 0] [   45/  468] time: 51.0680, train_loss: 1.08280551, train_accuracy: 0.7500, test_Accuracy: 0.7872\n",
      "Epoch: [ 0] [   46/  468] time: 52.0030, train_loss: 0.86072141, train_accuracy: 0.8359, test_Accuracy: 0.7898\n",
      "Epoch: [ 0] [   47/  468] time: 53.0080, train_loss: 0.95200527, train_accuracy: 0.8125, test_Accuracy: 0.7921\n",
      "Epoch: [ 0] [   48/  468] time: 54.0780, train_loss: 1.06876707, train_accuracy: 0.7656, test_Accuracy: 0.7946\n",
      "Epoch: [ 0] [   49/  468] time: 55.1460, train_loss: 0.97730100, train_accuracy: 0.7812, test_Accuracy: 0.7990\n",
      "Epoch: [ 0] [   50/  468] time: 56.1750, train_loss: 0.86393309, train_accuracy: 0.8359, test_Accuracy: 0.8047\n",
      "Epoch: [ 0] [   51/  468] time: 57.1900, train_loss: 1.07083535, train_accuracy: 0.8203, test_Accuracy: 0.8076\n",
      "Epoch: [ 0] [   52/  468] time: 58.1570, train_loss: 1.01774240, train_accuracy: 0.7578, test_Accuracy: 0.8095\n",
      "Epoch: [ 0] [   53/  468] time: 59.1340, train_loss: 0.94376910, train_accuracy: 0.7969, test_Accuracy: 0.8095\n",
      "Epoch: [ 0] [   54/  468] time: 60.1200, train_loss: 1.02633500, train_accuracy: 0.7578, test_Accuracy: 0.8094\n",
      "Epoch: [ 0] [   55/  468] time: 61.0780, train_loss: 1.09147823, train_accuracy: 0.7578, test_Accuracy: 0.8102\n",
      "Epoch: [ 0] [   56/  468] time: 62.0490, train_loss: 1.11989784, train_accuracy: 0.8203, test_Accuracy: 0.8095\n",
      "Epoch: [ 0] [   57/  468] time: 63.0090, train_loss: 0.93744743, train_accuracy: 0.8281, test_Accuracy: 0.8104\n",
      "Epoch: [ 0] [   58/  468] time: 64.0120, train_loss: 0.81151247, train_accuracy: 0.7578, test_Accuracy: 0.8122\n",
      "Epoch: [ 0] [   59/  468] time: 65.0180, train_loss: 0.99668044, train_accuracy: 0.8047, test_Accuracy: 0.8126\n",
      "Epoch: [ 0] [   60/  468] time: 65.9810, train_loss: 0.79892838, train_accuracy: 0.8203, test_Accuracy: 0.8132\n",
      "Epoch: [ 0] [   61/  468] time: 66.9740, train_loss: 0.84953606, train_accuracy: 0.8281, test_Accuracy: 0.8139\n",
      "Epoch: [ 0] [   62/  468] time: 67.9740, train_loss: 0.73229802, train_accuracy: 0.8672, test_Accuracy: 0.8157\n",
      "Epoch: [ 0] [   63/  468] time: 69.2360, train_loss: 0.82873213, train_accuracy: 0.8203, test_Accuracy: 0.8181\n",
      "Epoch: [ 0] [   64/  468] time: 70.1600, train_loss: 0.89212942, train_accuracy: 0.7656, test_Accuracy: 0.8199\n",
      "Epoch: [ 0] [   65/  468] time: 71.0890, train_loss: 0.87329996, train_accuracy: 0.8047, test_Accuracy: 0.8221\n",
      "Epoch: [ 0] [   66/  468] time: 72.0320, train_loss: 0.82154977, train_accuracy: 0.7969, test_Accuracy: 0.8254\n",
      "Epoch: [ 0] [   67/  468] time: 72.9810, train_loss: 0.76391757, train_accuracy: 0.7891, test_Accuracy: 0.8289\n",
      "Epoch: [ 0] [   68/  468] time: 73.9780, train_loss: 0.84184277, train_accuracy: 0.7578, test_Accuracy: 0.8321\n",
      "Epoch: [ 0] [   69/  468] time: 74.9540, train_loss: 0.79189128, train_accuracy: 0.8438, test_Accuracy: 0.8362\n",
      "Epoch: [ 0] [   70/  468] time: 75.9250, train_loss: 0.61303031, train_accuracy: 0.8906, test_Accuracy: 0.8393\n",
      "Epoch: [ 0] [   71/  468] time: 76.8900, train_loss: 0.69352043, train_accuracy: 0.8750, test_Accuracy: 0.8413\n",
      "Epoch: [ 0] [   72/  468] time: 77.8040, train_loss: 0.72172225, train_accuracy: 0.8438, test_Accuracy: 0.8430\n",
      "Epoch: [ 0] [   73/  468] time: 78.9640, train_loss: 0.64447725, train_accuracy: 0.8672, test_Accuracy: 0.8457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   74/  468] time: 80.0270, train_loss: 0.64780682, train_accuracy: 0.8672, test_Accuracy: 0.8471\n",
      "Epoch: [ 0] [   75/  468] time: 81.1110, train_loss: 0.83692259, train_accuracy: 0.8438, test_Accuracy: 0.8492\n",
      "Epoch: [ 0] [   76/  468] time: 82.2250, train_loss: 0.78415585, train_accuracy: 0.8438, test_Accuracy: 0.8519\n",
      "Epoch: [ 0] [   77/  468] time: 83.2860, train_loss: 0.74644947, train_accuracy: 0.8750, test_Accuracy: 0.8533\n",
      "Epoch: [ 0] [   78/  468] time: 84.4840, train_loss: 0.68473423, train_accuracy: 0.8281, test_Accuracy: 0.8547\n",
      "Epoch: [ 0] [   79/  468] time: 85.6970, train_loss: 0.62101716, train_accuracy: 0.8125, test_Accuracy: 0.8547\n",
      "Epoch: [ 0] [   80/  468] time: 86.7940, train_loss: 0.81125563, train_accuracy: 0.8125, test_Accuracy: 0.8558\n",
      "Epoch: [ 0] [   81/  468] time: 88.2030, train_loss: 0.78143823, train_accuracy: 0.7500, test_Accuracy: 0.8561\n",
      "Epoch: [ 0] [   82/  468] time: 89.5700, train_loss: 0.74502528, train_accuracy: 0.8438, test_Accuracy: 0.8564\n",
      "Epoch: [ 0] [   83/  468] time: 91.1680, train_loss: 0.60918534, train_accuracy: 0.8906, test_Accuracy: 0.8564\n",
      "Epoch: [ 0] [   84/  468] time: 92.5530, train_loss: 0.83569717, train_accuracy: 0.8359, test_Accuracy: 0.8550\n",
      "Epoch: [ 0] [   85/  468] time: 93.5860, train_loss: 0.59267330, train_accuracy: 0.8594, test_Accuracy: 0.8537\n",
      "Epoch: [ 0] [   86/  468] time: 94.5390, train_loss: 0.74148005, train_accuracy: 0.7891, test_Accuracy: 0.8546\n",
      "Epoch: [ 0] [   87/  468] time: 95.4960, train_loss: 0.72851157, train_accuracy: 0.8750, test_Accuracy: 0.8548\n",
      "Epoch: [ 0] [   88/  468] time: 96.4090, train_loss: 0.93927395, train_accuracy: 0.8047, test_Accuracy: 0.8556\n",
      "Epoch: [ 0] [   89/  468] time: 97.3670, train_loss: 0.60529071, train_accuracy: 0.8438, test_Accuracy: 0.8571\n",
      "Epoch: [ 0] [   90/  468] time: 98.5200, train_loss: 0.68666202, train_accuracy: 0.8594, test_Accuracy: 0.8584\n",
      "Epoch: [ 0] [   91/  468] time: 99.8500, train_loss: 0.71453488, train_accuracy: 0.8125, test_Accuracy: 0.8606\n",
      "Epoch: [ 0] [   92/  468] time: 100.7660, train_loss: 0.42406815, train_accuracy: 0.8750, test_Accuracy: 0.8624\n",
      "Epoch: [ 0] [   93/  468] time: 101.6830, train_loss: 0.57716244, train_accuracy: 0.8984, test_Accuracy: 0.8642\n",
      "Epoch: [ 0] [   94/  468] time: 102.5850, train_loss: 0.49512899, train_accuracy: 0.8594, test_Accuracy: 0.8656\n",
      "Epoch: [ 0] [   95/  468] time: 103.5020, train_loss: 0.70962518, train_accuracy: 0.8203, test_Accuracy: 0.8671\n",
      "Epoch: [ 0] [   96/  468] time: 104.4250, train_loss: 0.45333880, train_accuracy: 0.8750, test_Accuracy: 0.8693\n",
      "Epoch: [ 0] [   97/  468] time: 105.3380, train_loss: 0.65573627, train_accuracy: 0.8828, test_Accuracy: 0.8704\n",
      "Epoch: [ 0] [   98/  468] time: 106.2510, train_loss: 0.64227486, train_accuracy: 0.8828, test_Accuracy: 0.8723\n",
      "Epoch: [ 0] [   99/  468] time: 107.1840, train_loss: 0.65096390, train_accuracy: 0.8672, test_Accuracy: 0.8748\n",
      "Epoch: [ 0] [  100/  468] time: 108.0960, train_loss: 0.58013028, train_accuracy: 0.8906, test_Accuracy: 0.8780\n",
      "Epoch: [ 0] [  101/  468] time: 109.0070, train_loss: 0.68431002, train_accuracy: 0.8516, test_Accuracy: 0.8802\n",
      "Epoch: [ 0] [  102/  468] time: 109.9250, train_loss: 0.51113790, train_accuracy: 0.8906, test_Accuracy: 0.8822\n",
      "Epoch: [ 0] [  103/  468] time: 110.8480, train_loss: 0.48381841, train_accuracy: 0.8906, test_Accuracy: 0.8832\n",
      "Epoch: [ 0] [  104/  468] time: 111.7590, train_loss: 0.68433893, train_accuracy: 0.8984, test_Accuracy: 0.8839\n",
      "Epoch: [ 0] [  105/  468] time: 112.6640, train_loss: 0.58168977, train_accuracy: 0.9141, test_Accuracy: 0.8848\n",
      "Epoch: [ 0] [  106/  468] time: 113.5970, train_loss: 0.71114135, train_accuracy: 0.8438, test_Accuracy: 0.8852\n",
      "Epoch: [ 0] [  107/  468] time: 114.5120, train_loss: 0.56458664, train_accuracy: 0.9141, test_Accuracy: 0.8857\n",
      "Epoch: [ 0] [  108/  468] time: 115.4220, train_loss: 0.80470312, train_accuracy: 0.8125, test_Accuracy: 0.8866\n",
      "Epoch: [ 0] [  109/  468] time: 116.3400, train_loss: 0.50998402, train_accuracy: 0.9141, test_Accuracy: 0.8879\n",
      "Epoch: [ 0] [  110/  468] time: 117.2760, train_loss: 0.53342611, train_accuracy: 0.8594, test_Accuracy: 0.8881\n",
      "Epoch: [ 0] [  111/  468] time: 118.1860, train_loss: 0.42978281, train_accuracy: 0.9062, test_Accuracy: 0.8887\n",
      "Epoch: [ 0] [  112/  468] time: 119.1810, train_loss: 0.62476629, train_accuracy: 0.8984, test_Accuracy: 0.8889\n",
      "Epoch: [ 0] [  113/  468] time: 120.1080, train_loss: 0.61184108, train_accuracy: 0.8672, test_Accuracy: 0.8887\n",
      "Epoch: [ 0] [  114/  468] time: 121.0150, train_loss: 0.50290668, train_accuracy: 0.9375, test_Accuracy: 0.8894\n",
      "Epoch: [ 0] [  115/  468] time: 121.9470, train_loss: 0.64814973, train_accuracy: 0.8906, test_Accuracy: 0.8889\n",
      "Epoch: [ 0] [  116/  468] time: 122.8820, train_loss: 0.49010542, train_accuracy: 0.8906, test_Accuracy: 0.8890\n",
      "Epoch: [ 0] [  117/  468] time: 123.7900, train_loss: 0.66575384, train_accuracy: 0.8438, test_Accuracy: 0.8891\n",
      "Epoch: [ 0] [  118/  468] time: 124.7220, train_loss: 0.63943779, train_accuracy: 0.8516, test_Accuracy: 0.8893\n",
      "Epoch: [ 0] [  119/  468] time: 125.6270, train_loss: 0.45824242, train_accuracy: 0.9062, test_Accuracy: 0.8899\n",
      "Epoch: [ 0] [  120/  468] time: 126.5630, train_loss: 0.59583962, train_accuracy: 0.9219, test_Accuracy: 0.8900\n",
      "Epoch: [ 0] [  121/  468] time: 127.4690, train_loss: 0.48524499, train_accuracy: 0.8984, test_Accuracy: 0.8901\n",
      "Epoch: [ 0] [  122/  468] time: 128.3790, train_loss: 0.62057167, train_accuracy: 0.8828, test_Accuracy: 0.8912\n",
      "Epoch: [ 0] [  123/  468] time: 129.3070, train_loss: 0.53399640, train_accuracy: 0.9062, test_Accuracy: 0.8919\n",
      "Epoch: [ 0] [  124/  468] time: 130.2140, train_loss: 0.46701521, train_accuracy: 0.8906, test_Accuracy: 0.8932\n",
      "Epoch: [ 0] [  125/  468] time: 131.1280, train_loss: 0.44533855, train_accuracy: 0.9219, test_Accuracy: 0.8945\n",
      "Epoch: [ 0] [  126/  468] time: 132.0360, train_loss: 0.45617631, train_accuracy: 0.9609, test_Accuracy: 0.8955\n",
      "Epoch: [ 0] [  127/  468] time: 132.9540, train_loss: 0.44922882, train_accuracy: 0.9062, test_Accuracy: 0.8962\n",
      "Epoch: [ 0] [  128/  468] time: 133.8590, train_loss: 0.57101762, train_accuracy: 0.8984, test_Accuracy: 0.8969\n",
      "Epoch: [ 0] [  129/  468] time: 134.7920, train_loss: 0.47144994, train_accuracy: 0.8828, test_Accuracy: 0.8980\n",
      "Epoch: [ 0] [  130/  468] time: 135.7450, train_loss: 0.52283013, train_accuracy: 0.8906, test_Accuracy: 0.8989\n",
      "Epoch: [ 0] [  131/  468] time: 136.6520, train_loss: 0.49886501, train_accuracy: 0.8984, test_Accuracy: 0.8991\n",
      "Epoch: [ 0] [  132/  468] time: 137.5560, train_loss: 0.48852670, train_accuracy: 0.9297, test_Accuracy: 0.8996\n",
      "Epoch: [ 0] [  133/  468] time: 138.4750, train_loss: 0.52355927, train_accuracy: 0.8516, test_Accuracy: 0.9001\n",
      "Epoch: [ 0] [  134/  468] time: 139.3930, train_loss: 0.64621913, train_accuracy: 0.8516, test_Accuracy: 0.8994\n",
      "Epoch: [ 0] [  135/  468] time: 140.3000, train_loss: 0.46960455, train_accuracy: 0.8984, test_Accuracy: 0.9002\n",
      "Epoch: [ 0] [  136/  468] time: 141.2120, train_loss: 0.49872029, train_accuracy: 0.9062, test_Accuracy: 0.9007\n",
      "Epoch: [ 0] [  137/  468] time: 142.1360, train_loss: 0.43193889, train_accuracy: 0.9375, test_Accuracy: 0.9011\n",
      "Epoch: [ 0] [  138/  468] time: 143.0440, train_loss: 0.54250228, train_accuracy: 0.8984, test_Accuracy: 0.9011\n",
      "Epoch: [ 0] [  139/  468] time: 143.9620, train_loss: 0.41271791, train_accuracy: 0.8750, test_Accuracy: 0.9017\n",
      "Epoch: [ 0] [  140/  468] time: 144.8890, train_loss: 0.69397545, train_accuracy: 0.8516, test_Accuracy: 0.9014\n",
      "Epoch: [ 0] [  141/  468] time: 145.8000, train_loss: 0.44792762, train_accuracy: 0.9219, test_Accuracy: 0.9010\n",
      "Epoch: [ 0] [  142/  468] time: 146.7100, train_loss: 0.38937062, train_accuracy: 0.9375, test_Accuracy: 0.9019\n",
      "Epoch: [ 0] [  143/  468] time: 147.6150, train_loss: 0.53035331, train_accuracy: 0.9297, test_Accuracy: 0.9024\n",
      "Epoch: [ 0] [  144/  468] time: 148.5950, train_loss: 0.55410755, train_accuracy: 0.9141, test_Accuracy: 0.9025\n",
      "Epoch: [ 0] [  145/  468] time: 149.5000, train_loss: 0.59952748, train_accuracy: 0.8906, test_Accuracy: 0.9020\n",
      "Epoch: [ 0] [  146/  468] time: 150.4060, train_loss: 0.51126552, train_accuracy: 0.8906, test_Accuracy: 0.9015\n",
      "Epoch: [ 0] [  147/  468] time: 151.3310, train_loss: 0.41055003, train_accuracy: 0.9062, test_Accuracy: 0.9015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  148/  468] time: 152.2340, train_loss: 0.55170256, train_accuracy: 0.8750, test_Accuracy: 0.9026\n",
      "Epoch: [ 0] [  149/  468] time: 153.1490, train_loss: 0.53146082, train_accuracy: 0.9219, test_Accuracy: 0.9025\n",
      "Epoch: [ 0] [  150/  468] time: 154.0610, train_loss: 0.67703849, train_accuracy: 0.8750, test_Accuracy: 0.9036\n",
      "Epoch: [ 0] [  151/  468] time: 154.9840, train_loss: 0.43065012, train_accuracy: 0.8828, test_Accuracy: 0.9034\n",
      "Epoch: [ 0] [  152/  468] time: 155.8970, train_loss: 0.43496424, train_accuracy: 0.9297, test_Accuracy: 0.9036\n",
      "Epoch: [ 0] [  153/  468] time: 156.8080, train_loss: 0.45682102, train_accuracy: 0.8906, test_Accuracy: 0.9036\n",
      "Epoch: [ 0] [  154/  468] time: 157.7340, train_loss: 0.44612646, train_accuracy: 0.9375, test_Accuracy: 0.9035\n",
      "Epoch: [ 0] [  155/  468] time: 158.6390, train_loss: 0.61118728, train_accuracy: 0.9062, test_Accuracy: 0.9031\n",
      "Epoch: [ 0] [  156/  468] time: 159.6110, train_loss: 0.51363599, train_accuracy: 0.9062, test_Accuracy: 0.9026\n",
      "Epoch: [ 0] [  157/  468] time: 160.5410, train_loss: 0.50834596, train_accuracy: 0.8750, test_Accuracy: 0.9019\n",
      "Epoch: [ 0] [  158/  468] time: 161.4490, train_loss: 0.44069022, train_accuracy: 0.9141, test_Accuracy: 0.9026\n",
      "Epoch: [ 0] [  159/  468] time: 162.3510, train_loss: 0.49923390, train_accuracy: 0.9453, test_Accuracy: 0.9026\n",
      "Epoch: [ 0] [  160/  468] time: 163.2590, train_loss: 0.45982099, train_accuracy: 0.9297, test_Accuracy: 0.9024\n",
      "Epoch: [ 0] [  161/  468] time: 164.1870, train_loss: 0.35887593, train_accuracy: 0.9531, test_Accuracy: 0.9022\n",
      "Epoch: [ 0] [  162/  468] time: 165.0970, train_loss: 0.62212551, train_accuracy: 0.8672, test_Accuracy: 0.9028\n",
      "Epoch: [ 0] [  163/  468] time: 166.0130, train_loss: 0.28986624, train_accuracy: 0.9375, test_Accuracy: 0.9031\n",
      "Epoch: [ 0] [  164/  468] time: 166.9530, train_loss: 0.44075114, train_accuracy: 0.9062, test_Accuracy: 0.9037\n",
      "Epoch: [ 0] [  165/  468] time: 167.8550, train_loss: 0.43304396, train_accuracy: 0.8984, test_Accuracy: 0.9054\n",
      "Epoch: [ 0] [  166/  468] time: 168.7600, train_loss: 0.55569416, train_accuracy: 0.8750, test_Accuracy: 0.9062\n",
      "Epoch: [ 0] [  167/  468] time: 169.6650, train_loss: 0.58144486, train_accuracy: 0.8828, test_Accuracy: 0.9065\n",
      "Epoch: [ 0] [  168/  468] time: 170.5800, train_loss: 0.54385936, train_accuracy: 0.9219, test_Accuracy: 0.9087\n",
      "Epoch: [ 0] [  169/  468] time: 171.4840, train_loss: 0.42989910, train_accuracy: 0.9453, test_Accuracy: 0.9091\n",
      "Epoch: [ 0] [  170/  468] time: 172.3920, train_loss: 0.57205063, train_accuracy: 0.8984, test_Accuracy: 0.9085\n",
      "Epoch: [ 0] [  171/  468] time: 173.3170, train_loss: 0.45270687, train_accuracy: 0.8906, test_Accuracy: 0.9089\n",
      "Epoch: [ 0] [  172/  468] time: 174.2280, train_loss: 0.45697907, train_accuracy: 0.8906, test_Accuracy: 0.9093\n",
      "Epoch: [ 0] [  173/  468] time: 175.1320, train_loss: 0.40738204, train_accuracy: 0.9453, test_Accuracy: 0.9098\n",
      "Epoch: [ 0] [  174/  468] time: 176.0430, train_loss: 0.50905395, train_accuracy: 0.9062, test_Accuracy: 0.9097\n",
      "Epoch: [ 0] [  175/  468] time: 176.9640, train_loss: 0.48572233, train_accuracy: 0.9062, test_Accuracy: 0.9114\n",
      "Epoch: [ 0] [  176/  468] time: 177.8750, train_loss: 0.65291452, train_accuracy: 0.8750, test_Accuracy: 0.9114\n",
      "Epoch: [ 0] [  177/  468] time: 178.7770, train_loss: 0.50200230, train_accuracy: 0.8672, test_Accuracy: 0.9119\n",
      "Epoch: [ 0] [  178/  468] time: 179.7000, train_loss: 0.37146157, train_accuracy: 0.9219, test_Accuracy: 0.9122\n",
      "Epoch: [ 0] [  179/  468] time: 180.6060, train_loss: 0.58605760, train_accuracy: 0.8984, test_Accuracy: 0.9129\n",
      "Epoch: [ 0] [  180/  468] time: 181.5100, train_loss: 0.54427868, train_accuracy: 0.9062, test_Accuracy: 0.9135\n",
      "Epoch: [ 0] [  181/  468] time: 182.4370, train_loss: 0.58074325, train_accuracy: 0.8984, test_Accuracy: 0.9138\n",
      "Epoch: [ 0] [  182/  468] time: 183.3500, train_loss: 0.37935114, train_accuracy: 0.9375, test_Accuracy: 0.9136\n",
      "Epoch: [ 0] [  183/  468] time: 184.2760, train_loss: 0.48405293, train_accuracy: 0.9062, test_Accuracy: 0.9138\n",
      "Epoch: [ 0] [  184/  468] time: 185.1760, train_loss: 0.44263896, train_accuracy: 0.9062, test_Accuracy: 0.9137\n",
      "Epoch: [ 0] [  185/  468] time: 186.1130, train_loss: 0.43970329, train_accuracy: 0.8828, test_Accuracy: 0.9136\n",
      "Epoch: [ 0] [  186/  468] time: 187.0200, train_loss: 0.51401603, train_accuracy: 0.9062, test_Accuracy: 0.9135\n",
      "Epoch: [ 0] [  187/  468] time: 187.9220, train_loss: 0.41783455, train_accuracy: 0.9141, test_Accuracy: 0.9135\n",
      "Epoch: [ 0] [  188/  468] time: 188.8420, train_loss: 0.48191139, train_accuracy: 0.9062, test_Accuracy: 0.9132\n",
      "Epoch: [ 0] [  189/  468] time: 189.7460, train_loss: 0.51167810, train_accuracy: 0.9062, test_Accuracy: 0.9131\n",
      "Epoch: [ 0] [  190/  468] time: 190.6660, train_loss: 0.33691114, train_accuracy: 0.9453, test_Accuracy: 0.9134\n",
      "Epoch: [ 0] [  191/  468] time: 191.5820, train_loss: 0.46953848, train_accuracy: 0.9219, test_Accuracy: 0.9135\n",
      "Epoch: [ 0] [  192/  468] time: 192.5060, train_loss: 0.38395554, train_accuracy: 0.9219, test_Accuracy: 0.9136\n",
      "Epoch: [ 0] [  193/  468] time: 193.4140, train_loss: 0.46114248, train_accuracy: 0.9531, test_Accuracy: 0.9142\n",
      "Epoch: [ 0] [  194/  468] time: 194.3300, train_loss: 0.37018606, train_accuracy: 0.9375, test_Accuracy: 0.9148\n",
      "Epoch: [ 0] [  195/  468] time: 195.2720, train_loss: 0.57710302, train_accuracy: 0.9062, test_Accuracy: 0.9150\n",
      "Epoch: [ 0] [  196/  468] time: 196.1740, train_loss: 0.39622760, train_accuracy: 0.9453, test_Accuracy: 0.9148\n",
      "Epoch: [ 0] [  197/  468] time: 197.0890, train_loss: 0.51702917, train_accuracy: 0.9219, test_Accuracy: 0.9150\n",
      "Epoch: [ 0] [  198/  468] time: 198.0090, train_loss: 0.39748186, train_accuracy: 0.8750, test_Accuracy: 0.9153\n",
      "Epoch: [ 0] [  199/  468] time: 198.9150, train_loss: 0.26350886, train_accuracy: 0.9688, test_Accuracy: 0.9161\n",
      "Epoch: [ 0] [  200/  468] time: 199.8280, train_loss: 0.48156017, train_accuracy: 0.8984, test_Accuracy: 0.9164\n",
      "Epoch: [ 0] [  201/  468] time: 200.7630, train_loss: 0.45296961, train_accuracy: 0.8984, test_Accuracy: 0.9165\n",
      "Epoch: [ 0] [  202/  468] time: 201.6860, train_loss: 0.40145290, train_accuracy: 0.8906, test_Accuracy: 0.9174\n",
      "Epoch: [ 0] [  203/  468] time: 202.6100, train_loss: 0.52016187, train_accuracy: 0.9297, test_Accuracy: 0.9181\n",
      "Epoch: [ 0] [  204/  468] time: 203.5780, train_loss: 0.38993537, train_accuracy: 0.9375, test_Accuracy: 0.9184\n",
      "Epoch: [ 0] [  205/  468] time: 204.5800, train_loss: 0.36329395, train_accuracy: 0.9297, test_Accuracy: 0.9183\n",
      "Epoch: [ 0] [  206/  468] time: 205.5480, train_loss: 0.54141045, train_accuracy: 0.8984, test_Accuracy: 0.9187\n",
      "Epoch: [ 0] [  207/  468] time: 206.5310, train_loss: 0.45922083, train_accuracy: 0.8828, test_Accuracy: 0.9194\n",
      "Epoch: [ 0] [  208/  468] time: 207.5410, train_loss: 0.50595003, train_accuracy: 0.8750, test_Accuracy: 0.9196\n",
      "Epoch: [ 0] [  209/  468] time: 208.5830, train_loss: 0.55428338, train_accuracy: 0.8516, test_Accuracy: 0.9199\n",
      "Epoch: [ 0] [  210/  468] time: 209.5100, train_loss: 0.61071682, train_accuracy: 0.8906, test_Accuracy: 0.9201\n",
      "Epoch: [ 0] [  211/  468] time: 210.4120, train_loss: 0.33999971, train_accuracy: 0.9062, test_Accuracy: 0.9213\n",
      "Epoch: [ 0] [  212/  468] time: 211.3340, train_loss: 0.31299299, train_accuracy: 0.9141, test_Accuracy: 0.9214\n",
      "Epoch: [ 0] [  213/  468] time: 212.2380, train_loss: 0.47409636, train_accuracy: 0.8828, test_Accuracy: 0.9215\n",
      "Epoch: [ 0] [  214/  468] time: 213.1430, train_loss: 0.55119252, train_accuracy: 0.8828, test_Accuracy: 0.9222\n",
      "Epoch: [ 0] [  215/  468] time: 214.0710, train_loss: 0.47857577, train_accuracy: 0.9141, test_Accuracy: 0.9225\n",
      "Epoch: [ 0] [  216/  468] time: 214.9820, train_loss: 0.56448388, train_accuracy: 0.8984, test_Accuracy: 0.9231\n",
      "Epoch: [ 0] [  217/  468] time: 215.8940, train_loss: 0.35204852, train_accuracy: 0.9375, test_Accuracy: 0.9232\n",
      "Epoch: [ 0] [  218/  468] time: 216.8070, train_loss: 0.56382453, train_accuracy: 0.8828, test_Accuracy: 0.9238\n",
      "Epoch: [ 0] [  219/  468] time: 217.8200, train_loss: 0.58329535, train_accuracy: 0.8984, test_Accuracy: 0.9235\n",
      "Epoch: [ 0] [  220/  468] time: 218.8610, train_loss: 0.38565701, train_accuracy: 0.9141, test_Accuracy: 0.9244\n",
      "Epoch: [ 0] [  221/  468] time: 219.9230, train_loss: 0.24959946, train_accuracy: 0.9375, test_Accuracy: 0.9244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  222/  468] time: 221.1850, train_loss: 0.29428101, train_accuracy: 0.9141, test_Accuracy: 0.9241\n",
      "Epoch: [ 0] [  223/  468] time: 222.2190, train_loss: 0.30294585, train_accuracy: 0.9141, test_Accuracy: 0.9245\n",
      "Epoch: [ 0] [  224/  468] time: 223.2040, train_loss: 0.41239381, train_accuracy: 0.9062, test_Accuracy: 0.9242\n",
      "Epoch: [ 0] [  225/  468] time: 224.1520, train_loss: 0.38056785, train_accuracy: 0.9141, test_Accuracy: 0.9240\n",
      "Epoch: [ 0] [  226/  468] time: 225.0670, train_loss: 0.44498488, train_accuracy: 0.8984, test_Accuracy: 0.9238\n",
      "Epoch: [ 0] [  227/  468] time: 226.6620, train_loss: 0.39398479, train_accuracy: 0.9062, test_Accuracy: 0.9234\n",
      "Epoch: [ 0] [  228/  468] time: 227.7040, train_loss: 0.34598559, train_accuracy: 0.9219, test_Accuracy: 0.9240\n",
      "Epoch: [ 0] [  229/  468] time: 228.6740, train_loss: 0.46817762, train_accuracy: 0.9141, test_Accuracy: 0.9232\n",
      "Epoch: [ 0] [  230/  468] time: 229.6320, train_loss: 0.42734009, train_accuracy: 0.9141, test_Accuracy: 0.9224\n",
      "Epoch: [ 0] [  231/  468] time: 230.5480, train_loss: 0.54255843, train_accuracy: 0.8828, test_Accuracy: 0.9222\n",
      "Epoch: [ 0] [  232/  468] time: 231.4650, train_loss: 0.46407875, train_accuracy: 0.9219, test_Accuracy: 0.9217\n",
      "Epoch: [ 0] [  233/  468] time: 232.3840, train_loss: 0.51281661, train_accuracy: 0.9219, test_Accuracy: 0.9212\n",
      "Epoch: [ 0] [  234/  468] time: 233.3220, train_loss: 0.49892682, train_accuracy: 0.8906, test_Accuracy: 0.9205\n",
      "Epoch: [ 0] [  235/  468] time: 234.2410, train_loss: 0.62739086, train_accuracy: 0.8281, test_Accuracy: 0.9208\n",
      "Epoch: [ 0] [  236/  468] time: 235.1730, train_loss: 0.34862283, train_accuracy: 0.9062, test_Accuracy: 0.9199\n",
      "Epoch: [ 0] [  237/  468] time: 236.1320, train_loss: 0.47495690, train_accuracy: 0.8828, test_Accuracy: 0.9192\n",
      "Epoch: [ 0] [  238/  468] time: 237.0880, train_loss: 0.34406775, train_accuracy: 0.9062, test_Accuracy: 0.9183\n",
      "Epoch: [ 0] [  239/  468] time: 238.3940, train_loss: 0.43850586, train_accuracy: 0.9062, test_Accuracy: 0.9179\n",
      "Epoch: [ 0] [  240/  468] time: 239.5910, train_loss: 0.35578370, train_accuracy: 0.9375, test_Accuracy: 0.9180\n",
      "Epoch: [ 0] [  241/  468] time: 240.9520, train_loss: 0.51607066, train_accuracy: 0.9141, test_Accuracy: 0.9171\n",
      "Epoch: [ 0] [  242/  468] time: 242.1410, train_loss: 0.32544082, train_accuracy: 0.9453, test_Accuracy: 0.9168\n",
      "Epoch: [ 0] [  243/  468] time: 243.3560, train_loss: 0.33225924, train_accuracy: 0.9375, test_Accuracy: 0.9169\n",
      "Epoch: [ 0] [  244/  468] time: 244.4200, train_loss: 0.43026140, train_accuracy: 0.8984, test_Accuracy: 0.9166\n",
      "Epoch: [ 0] [  245/  468] time: 245.3620, train_loss: 0.45766768, train_accuracy: 0.8984, test_Accuracy: 0.9164\n",
      "Epoch: [ 0] [  246/  468] time: 246.3140, train_loss: 0.41510057, train_accuracy: 0.9141, test_Accuracy: 0.9160\n",
      "Epoch: [ 0] [  247/  468] time: 247.2530, train_loss: 0.41065058, train_accuracy: 0.9141, test_Accuracy: 0.9150\n",
      "Epoch: [ 0] [  248/  468] time: 248.1750, train_loss: 0.39875782, train_accuracy: 0.8984, test_Accuracy: 0.9146\n",
      "Epoch: [ 0] [  249/  468] time: 249.1120, train_loss: 0.40694767, train_accuracy: 0.9219, test_Accuracy: 0.9146\n",
      "Epoch: [ 0] [  250/  468] time: 250.0400, train_loss: 0.36356962, train_accuracy: 0.8750, test_Accuracy: 0.9141\n",
      "Epoch: [ 0] [  251/  468] time: 251.0360, train_loss: 0.42736727, train_accuracy: 0.8750, test_Accuracy: 0.9150\n",
      "Epoch: [ 0] [  252/  468] time: 252.0190, train_loss: 0.48333162, train_accuracy: 0.9219, test_Accuracy: 0.9155\n",
      "Epoch: [ 0] [  253/  468] time: 253.0130, train_loss: 0.21564184, train_accuracy: 0.9219, test_Accuracy: 0.9169\n",
      "Epoch: [ 0] [  254/  468] time: 254.1880, train_loss: 0.20940143, train_accuracy: 0.9531, test_Accuracy: 0.9169\n",
      "Epoch: [ 0] [  255/  468] time: 255.3020, train_loss: 0.38608211, train_accuracy: 0.9297, test_Accuracy: 0.9174\n",
      "Epoch: [ 0] [  256/  468] time: 256.2440, train_loss: 0.32150292, train_accuracy: 0.9609, test_Accuracy: 0.9179\n",
      "Epoch: [ 0] [  257/  468] time: 257.1590, train_loss: 0.27820021, train_accuracy: 0.9766, test_Accuracy: 0.9183\n",
      "Epoch: [ 0] [  258/  468] time: 258.0910, train_loss: 0.44529125, train_accuracy: 0.9297, test_Accuracy: 0.9190\n",
      "Epoch: [ 0] [  259/  468] time: 259.0130, train_loss: 0.28431731, train_accuracy: 0.9375, test_Accuracy: 0.9199\n",
      "Epoch: [ 0] [  260/  468] time: 260.0800, train_loss: 0.42962754, train_accuracy: 0.9219, test_Accuracy: 0.9199\n",
      "Epoch: [ 0] [  261/  468] time: 261.1600, train_loss: 0.38750041, train_accuracy: 0.9062, test_Accuracy: 0.9212\n",
      "Epoch: [ 0] [  262/  468] time: 262.1830, train_loss: 0.24407224, train_accuracy: 0.9688, test_Accuracy: 0.9220\n",
      "Epoch: [ 0] [  263/  468] time: 263.1090, train_loss: 0.22826825, train_accuracy: 0.9453, test_Accuracy: 0.9226\n",
      "Epoch: [ 0] [  264/  468] time: 264.0630, train_loss: 0.44749355, train_accuracy: 0.9297, test_Accuracy: 0.9230\n",
      "Epoch: [ 0] [  265/  468] time: 265.0700, train_loss: 0.40644789, train_accuracy: 0.9219, test_Accuracy: 0.9228\n",
      "Epoch: [ 0] [  266/  468] time: 266.0000, train_loss: 0.54326868, train_accuracy: 0.9062, test_Accuracy: 0.9233\n",
      "Epoch: [ 0] [  267/  468] time: 266.9710, train_loss: 0.39247710, train_accuracy: 0.9141, test_Accuracy: 0.9240\n",
      "Epoch: [ 0] [  268/  468] time: 267.9280, train_loss: 0.32771906, train_accuracy: 0.9453, test_Accuracy: 0.9242\n",
      "Epoch: [ 0] [  269/  468] time: 268.9750, train_loss: 0.32930243, train_accuracy: 0.9375, test_Accuracy: 0.9249\n",
      "Epoch: [ 0] [  270/  468] time: 270.0620, train_loss: 0.44622117, train_accuracy: 0.8828, test_Accuracy: 0.9251\n",
      "Epoch: [ 0] [  271/  468] time: 271.0640, train_loss: 0.58063251, train_accuracy: 0.9141, test_Accuracy: 0.9249\n",
      "Epoch: [ 0] [  272/  468] time: 271.9810, train_loss: 0.47165719, train_accuracy: 0.8984, test_Accuracy: 0.9260\n",
      "Epoch: [ 0] [  273/  468] time: 272.8940, train_loss: 0.31184679, train_accuracy: 0.9219, test_Accuracy: 0.9263\n",
      "Epoch: [ 0] [  274/  468] time: 273.9010, train_loss: 0.38286564, train_accuracy: 0.9375, test_Accuracy: 0.9269\n",
      "Epoch: [ 0] [  275/  468] time: 274.8430, train_loss: 0.34437475, train_accuracy: 0.9141, test_Accuracy: 0.9273\n",
      "Epoch: [ 0] [  276/  468] time: 275.8200, train_loss: 0.42758018, train_accuracy: 0.9219, test_Accuracy: 0.9272\n",
      "Epoch: [ 0] [  277/  468] time: 277.1910, train_loss: 0.51375401, train_accuracy: 0.9141, test_Accuracy: 0.9275\n",
      "Epoch: [ 0] [  278/  468] time: 278.1420, train_loss: 0.29350293, train_accuracy: 0.9609, test_Accuracy: 0.9277\n",
      "Epoch: [ 0] [  279/  468] time: 279.1410, train_loss: 0.42428252, train_accuracy: 0.9141, test_Accuracy: 0.9278\n",
      "Epoch: [ 0] [  280/  468] time: 280.1260, train_loss: 0.27288198, train_accuracy: 0.9297, test_Accuracy: 0.9277\n",
      "Epoch: [ 0] [  281/  468] time: 281.1460, train_loss: 0.48660338, train_accuracy: 0.9141, test_Accuracy: 0.9283\n",
      "Epoch: [ 0] [  282/  468] time: 282.1550, train_loss: 0.48975947, train_accuracy: 0.9062, test_Accuracy: 0.9281\n",
      "Epoch: [ 0] [  283/  468] time: 283.1060, train_loss: 0.40120929, train_accuracy: 0.9297, test_Accuracy: 0.9280\n",
      "Epoch: [ 0] [  284/  468] time: 284.0450, train_loss: 0.33514029, train_accuracy: 0.9062, test_Accuracy: 0.9274\n",
      "Epoch: [ 0] [  285/  468] time: 284.9590, train_loss: 0.26429269, train_accuracy: 0.9453, test_Accuracy: 0.9275\n",
      "Epoch: [ 0] [  286/  468] time: 285.8900, train_loss: 0.30471709, train_accuracy: 0.9453, test_Accuracy: 0.9274\n",
      "Epoch: [ 0] [  287/  468] time: 286.9040, train_loss: 0.41808379, train_accuracy: 0.9375, test_Accuracy: 0.9272\n",
      "Epoch: [ 0] [  288/  468] time: 287.9330, train_loss: 0.46826065, train_accuracy: 0.8906, test_Accuracy: 0.9273\n",
      "Epoch: [ 0] [  289/  468] time: 288.9290, train_loss: 0.29313719, train_accuracy: 0.9297, test_Accuracy: 0.9272\n",
      "Epoch: [ 0] [  290/  468] time: 289.9070, train_loss: 0.28797239, train_accuracy: 0.9609, test_Accuracy: 0.9273\n",
      "Epoch: [ 0] [  291/  468] time: 290.8820, train_loss: 0.38150162, train_accuracy: 0.9531, test_Accuracy: 0.9269\n",
      "Epoch: [ 0] [  292/  468] time: 291.8770, train_loss: 0.39823639, train_accuracy: 0.9453, test_Accuracy: 0.9267\n",
      "Epoch: [ 0] [  293/  468] time: 292.9630, train_loss: 0.31754085, train_accuracy: 0.9453, test_Accuracy: 0.9267\n",
      "Epoch: [ 0] [  294/  468] time: 293.9390, train_loss: 0.44220319, train_accuracy: 0.8906, test_Accuracy: 0.9266\n",
      "Epoch: [ 0] [  295/  468] time: 294.9170, train_loss: 0.55620122, train_accuracy: 0.8906, test_Accuracy: 0.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  296/  468] time: 295.9850, train_loss: 0.32158625, train_accuracy: 0.8906, test_Accuracy: 0.9280\n",
      "Epoch: [ 0] [  297/  468] time: 297.0080, train_loss: 0.40776360, train_accuracy: 0.9141, test_Accuracy: 0.9288\n",
      "Epoch: [ 0] [  298/  468] time: 297.9970, train_loss: 0.37081638, train_accuracy: 0.9297, test_Accuracy: 0.9294\n",
      "Epoch: [ 0] [  299/  468] time: 299.0300, train_loss: 0.37524706, train_accuracy: 0.9219, test_Accuracy: 0.9298\n",
      "Epoch: [ 0] [  300/  468] time: 300.0620, train_loss: 0.58745158, train_accuracy: 0.8906, test_Accuracy: 0.9297\n",
      "Epoch: [ 0] [  301/  468] time: 301.0240, train_loss: 0.38679159, train_accuracy: 0.9531, test_Accuracy: 0.9303\n",
      "Epoch: [ 0] [  302/  468] time: 302.0730, train_loss: 0.37519473, train_accuracy: 0.9141, test_Accuracy: 0.9303\n",
      "Epoch: [ 0] [  303/  468] time: 303.0630, train_loss: 0.36811507, train_accuracy: 0.9531, test_Accuracy: 0.9305\n",
      "Epoch: [ 0] [  304/  468] time: 304.0530, train_loss: 0.26677999, train_accuracy: 0.9688, test_Accuracy: 0.9315\n",
      "Epoch: [ 0] [  305/  468] time: 305.0520, train_loss: 0.28226602, train_accuracy: 0.9531, test_Accuracy: 0.9323\n",
      "Epoch: [ 0] [  306/  468] time: 306.0550, train_loss: 0.31279993, train_accuracy: 0.9531, test_Accuracy: 0.9322\n",
      "Epoch: [ 0] [  307/  468] time: 307.3620, train_loss: 0.23015153, train_accuracy: 0.9609, test_Accuracy: 0.9320\n",
      "Epoch: [ 0] [  308/  468] time: 308.3230, train_loss: 0.31055421, train_accuracy: 0.9375, test_Accuracy: 0.9327\n",
      "Epoch: [ 0] [  309/  468] time: 309.2840, train_loss: 0.28212190, train_accuracy: 0.9453, test_Accuracy: 0.9329\n",
      "Epoch: [ 0] [  310/  468] time: 310.4110, train_loss: 0.25207657, train_accuracy: 0.9453, test_Accuracy: 0.9333\n",
      "Epoch: [ 0] [  311/  468] time: 311.4400, train_loss: 0.34303716, train_accuracy: 0.9141, test_Accuracy: 0.9333\n",
      "Epoch: [ 0] [  312/  468] time: 312.4840, train_loss: 0.37312663, train_accuracy: 0.9375, test_Accuracy: 0.9327\n",
      "Epoch: [ 0] [  313/  468] time: 313.4200, train_loss: 0.42436945, train_accuracy: 0.9141, test_Accuracy: 0.9330\n",
      "Epoch: [ 0] [  314/  468] time: 314.4820, train_loss: 0.33250886, train_accuracy: 0.9141, test_Accuracy: 0.9325\n",
      "Epoch: [ 0] [  315/  468] time: 315.5140, train_loss: 0.27218282, train_accuracy: 0.9375, test_Accuracy: 0.9324\n",
      "Epoch: [ 0] [  316/  468] time: 316.4930, train_loss: 0.44233060, train_accuracy: 0.9141, test_Accuracy: 0.9325\n",
      "Epoch: [ 0] [  317/  468] time: 317.4820, train_loss: 0.34544602, train_accuracy: 0.9219, test_Accuracy: 0.9330\n",
      "Epoch: [ 0] [  318/  468] time: 318.4760, train_loss: 0.39496076, train_accuracy: 0.9219, test_Accuracy: 0.9328\n",
      "Epoch: [ 0] [  319/  468] time: 319.4470, train_loss: 0.44436446, train_accuracy: 0.9453, test_Accuracy: 0.9330\n",
      "Epoch: [ 0] [  320/  468] time: 320.6480, train_loss: 0.20401692, train_accuracy: 0.9844, test_Accuracy: 0.9328\n",
      "Epoch: [ 0] [  321/  468] time: 321.6420, train_loss: 0.22393355, train_accuracy: 0.9531, test_Accuracy: 0.9326\n",
      "Epoch: [ 0] [  322/  468] time: 322.5800, train_loss: 0.35197192, train_accuracy: 0.9375, test_Accuracy: 0.9324\n",
      "Epoch: [ 0] [  323/  468] time: 323.4940, train_loss: 0.43065822, train_accuracy: 0.9219, test_Accuracy: 0.9330\n",
      "Epoch: [ 0] [  324/  468] time: 324.5130, train_loss: 0.54147732, train_accuracy: 0.8750, test_Accuracy: 0.9329\n",
      "Epoch: [ 0] [  325/  468] time: 325.4710, train_loss: 0.37602276, train_accuracy: 0.9219, test_Accuracy: 0.9321\n",
      "Epoch: [ 0] [  326/  468] time: 326.4680, train_loss: 0.36416787, train_accuracy: 0.9375, test_Accuracy: 0.9321\n",
      "Epoch: [ 0] [  327/  468] time: 327.6640, train_loss: 0.30157816, train_accuracy: 0.9297, test_Accuracy: 0.9320\n",
      "Epoch: [ 0] [  328/  468] time: 328.7375, train_loss: 0.45858994, train_accuracy: 0.9375, test_Accuracy: 0.9315\n",
      "Epoch: [ 0] [  329/  468] time: 329.7600, train_loss: 0.37581283, train_accuracy: 0.9297, test_Accuracy: 0.9310\n",
      "Epoch: [ 0] [  330/  468] time: 330.9250, train_loss: 0.45992875, train_accuracy: 0.9141, test_Accuracy: 0.9308\n",
      "Epoch: [ 0] [  331/  468] time: 332.1550, train_loss: 0.32301462, train_accuracy: 0.9531, test_Accuracy: 0.9308\n",
      "Epoch: [ 0] [  332/  468] time: 333.1660, train_loss: 0.48509294, train_accuracy: 0.9219, test_Accuracy: 0.9310\n",
      "Epoch: [ 0] [  333/  468] time: 334.2066, train_loss: 0.38704076, train_accuracy: 0.9219, test_Accuracy: 0.9310\n",
      "Epoch: [ 0] [  334/  468] time: 335.1836, train_loss: 0.39012003, train_accuracy: 0.9297, test_Accuracy: 0.9309\n",
      "Epoch: [ 0] [  335/  468] time: 336.1566, train_loss: 0.39402044, train_accuracy: 0.9219, test_Accuracy: 0.9304\n",
      "Epoch: [ 0] [  336/  468] time: 337.2046, train_loss: 0.36435363, train_accuracy: 0.9297, test_Accuracy: 0.9303\n",
      "Epoch: [ 0] [  337/  468] time: 338.1966, train_loss: 0.17818345, train_accuracy: 0.9609, test_Accuracy: 0.9307\n",
      "Epoch: [ 0] [  338/  468] time: 339.1996, train_loss: 0.30252117, train_accuracy: 0.9609, test_Accuracy: 0.9309\n",
      "Epoch: [ 0] [  339/  468] time: 340.2726, train_loss: 0.37413323, train_accuracy: 0.9297, test_Accuracy: 0.9303\n",
      "Epoch: [ 0] [  340/  468] time: 341.2796, train_loss: 0.39036027, train_accuracy: 0.9219, test_Accuracy: 0.9306\n",
      "Epoch: [ 0] [  341/  468] time: 342.2706, train_loss: 0.29887399, train_accuracy: 0.9297, test_Accuracy: 0.9310\n",
      "Epoch: [ 0] [  342/  468] time: 343.2546, train_loss: 0.18930951, train_accuracy: 0.9609, test_Accuracy: 0.9313\n",
      "Epoch: [ 0] [  343/  468] time: 344.2486, train_loss: 0.51858151, train_accuracy: 0.9062, test_Accuracy: 0.9318\n",
      "Epoch: [ 0] [  344/  468] time: 345.2486, train_loss: 0.37896347, train_accuracy: 0.9297, test_Accuracy: 0.9325\n",
      "Epoch: [ 0] [  345/  468] time: 346.2226, train_loss: 0.35371140, train_accuracy: 0.9453, test_Accuracy: 0.9324\n",
      "Epoch: [ 0] [  346/  468] time: 347.2866, train_loss: 0.42645344, train_accuracy: 0.9453, test_Accuracy: 0.9331\n",
      "Epoch: [ 0] [  347/  468] time: 348.2696, train_loss: 0.20245799, train_accuracy: 0.9609, test_Accuracy: 0.9344\n",
      "Epoch: [ 0] [  348/  468] time: 349.2676, train_loss: 0.28802496, train_accuracy: 0.9453, test_Accuracy: 0.9360\n",
      "Epoch: [ 0] [  349/  468] time: 350.2806, train_loss: 0.46113199, train_accuracy: 0.9141, test_Accuracy: 0.9362\n",
      "Epoch: [ 0] [  350/  468] time: 351.3046, train_loss: 0.37719905, train_accuracy: 0.9219, test_Accuracy: 0.9371\n",
      "Epoch: [ 0] [  351/  468] time: 352.4196, train_loss: 0.27722412, train_accuracy: 0.9531, test_Accuracy: 0.9373\n",
      "Epoch: [ 0] [  352/  468] time: 353.4806, train_loss: 0.21681347, train_accuracy: 1.0000, test_Accuracy: 0.9378\n",
      "Epoch: [ 0] [  353/  468] time: 354.5026, train_loss: 0.25669861, train_accuracy: 0.9531, test_Accuracy: 0.9379\n",
      "Epoch: [ 0] [  354/  468] time: 355.5546, train_loss: 0.37406546, train_accuracy: 0.9375, test_Accuracy: 0.9382\n",
      "Epoch: [ 0] [  355/  468] time: 356.5531, train_loss: 0.36841398, train_accuracy: 0.9219, test_Accuracy: 0.9384\n",
      "Epoch: [ 0] [  356/  468] time: 357.6381, train_loss: 0.31487581, train_accuracy: 0.9375, test_Accuracy: 0.9390\n",
      "Epoch: [ 0] [  357/  468] time: 358.7961, train_loss: 0.23315282, train_accuracy: 0.9688, test_Accuracy: 0.9392\n",
      "Epoch: [ 0] [  358/  468] time: 359.8591, train_loss: 0.30684951, train_accuracy: 0.9766, test_Accuracy: 0.9389\n",
      "Epoch: [ 0] [  359/  468] time: 360.8901, train_loss: 0.24699141, train_accuracy: 0.9688, test_Accuracy: 0.9390\n",
      "Epoch: [ 0] [  360/  468] time: 361.8931, train_loss: 0.39016110, train_accuracy: 0.9141, test_Accuracy: 0.9390\n",
      "Epoch: [ 0] [  361/  468] time: 362.9541, train_loss: 0.30018342, train_accuracy: 0.9531, test_Accuracy: 0.9393\n",
      "Epoch: [ 0] [  362/  468] time: 363.9431, train_loss: 0.31537241, train_accuracy: 0.9453, test_Accuracy: 0.9390\n",
      "Epoch: [ 0] [  363/  468] time: 365.0451, train_loss: 0.34291834, train_accuracy: 0.9297, test_Accuracy: 0.9391\n",
      "Epoch: [ 0] [  364/  468] time: 366.1851, train_loss: 0.26572677, train_accuracy: 0.9609, test_Accuracy: 0.9384\n",
      "Epoch: [ 0] [  365/  468] time: 367.2541, train_loss: 0.42360672, train_accuracy: 0.9453, test_Accuracy: 0.9385\n",
      "Epoch: [ 0] [  366/  468] time: 368.1851, train_loss: 0.35219175, train_accuracy: 0.9375, test_Accuracy: 0.9389\n",
      "Epoch: [ 0] [  367/  468] time: 369.1971, train_loss: 0.31366795, train_accuracy: 0.9219, test_Accuracy: 0.9385\n",
      "Epoch: [ 0] [  368/  468] time: 370.1931, train_loss: 0.25286794, train_accuracy: 0.9688, test_Accuracy: 0.9389\n",
      "Epoch: [ 0] [  369/  468] time: 371.1781, train_loss: 0.27487421, train_accuracy: 0.9375, test_Accuracy: 0.9389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  370/  468] time: 372.2421, train_loss: 0.29227084, train_accuracy: 0.9453, test_Accuracy: 0.9386\n",
      "Epoch: [ 0] [  371/  468] time: 373.3921, train_loss: 0.40142655, train_accuracy: 0.9375, test_Accuracy: 0.9390\n",
      "Epoch: [ 0] [  372/  468] time: 374.5671, train_loss: 0.35455063, train_accuracy: 0.9453, test_Accuracy: 0.9400\n",
      "Epoch: [ 0] [  373/  468] time: 375.7831, train_loss: 0.35427326, train_accuracy: 0.9219, test_Accuracy: 0.9409\n",
      "Epoch: [ 0] [  374/  468] time: 376.8511, train_loss: 0.44320258, train_accuracy: 0.9375, test_Accuracy: 0.9416\n",
      "Epoch: [ 0] [  375/  468] time: 377.7701, train_loss: 0.34867671, train_accuracy: 0.9297, test_Accuracy: 0.9420\n",
      "Epoch: [ 0] [  376/  468] time: 378.7071, train_loss: 0.29911754, train_accuracy: 0.9141, test_Accuracy: 0.9425\n",
      "Epoch: [ 0] [  377/  468] time: 379.6221, train_loss: 0.30546081, train_accuracy: 0.9453, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  378/  468] time: 380.6101, train_loss: 0.55485737, train_accuracy: 0.8906, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  379/  468] time: 381.5451, train_loss: 0.26845717, train_accuracy: 0.9609, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  380/  468] time: 382.5581, train_loss: 0.31054214, train_accuracy: 0.9453, test_Accuracy: 0.9431\n",
      "Epoch: [ 0] [  381/  468] time: 383.5641, train_loss: 0.31288373, train_accuracy: 0.9297, test_Accuracy: 0.9430\n",
      "Epoch: [ 0] [  382/  468] time: 384.5791, train_loss: 0.39793363, train_accuracy: 0.9219, test_Accuracy: 0.9432\n",
      "Epoch: [ 0] [  383/  468] time: 385.5901, train_loss: 0.30002195, train_accuracy: 0.9453, test_Accuracy: 0.9429\n",
      "Epoch: [ 0] [  384/  468] time: 386.5461, train_loss: 0.25049302, train_accuracy: 0.9688, test_Accuracy: 0.9431\n",
      "Epoch: [ 0] [  385/  468] time: 387.4611, train_loss: 0.51942295, train_accuracy: 0.9219, test_Accuracy: 0.9428\n",
      "Epoch: [ 0] [  386/  468] time: 388.9811, train_loss: 0.43146393, train_accuracy: 0.9531, test_Accuracy: 0.9426\n",
      "Epoch: [ 0] [  387/  468] time: 389.9601, train_loss: 0.35122055, train_accuracy: 0.9375, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  388/  468] time: 390.9161, train_loss: 0.30133820, train_accuracy: 0.9531, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  389/  468] time: 392.0911, train_loss: 0.43572590, train_accuracy: 0.9297, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  390/  468] time: 393.1041, train_loss: 0.27325979, train_accuracy: 0.9375, test_Accuracy: 0.9427\n",
      "Epoch: [ 0] [  391/  468] time: 394.0941, train_loss: 0.42391980, train_accuracy: 0.9219, test_Accuracy: 0.9427\n",
      "Epoch: [ 0] [  392/  468] time: 395.1731, train_loss: 0.35440010, train_accuracy: 0.9141, test_Accuracy: 0.9420\n",
      "Epoch: [ 0] [  393/  468] time: 396.2641, train_loss: 0.27664828, train_accuracy: 0.9609, test_Accuracy: 0.9414\n",
      "Epoch: [ 0] [  394/  468] time: 397.4191, train_loss: 0.29903927, train_accuracy: 0.9609, test_Accuracy: 0.9414\n",
      "Epoch: [ 0] [  395/  468] time: 398.4841, train_loss: 0.28943145, train_accuracy: 0.9453, test_Accuracy: 0.9410\n",
      "Epoch: [ 0] [  396/  468] time: 399.4351, train_loss: 0.41996810, train_accuracy: 0.8828, test_Accuracy: 0.9412\n",
      "Epoch: [ 0] [  397/  468] time: 400.5251, train_loss: 0.37959334, train_accuracy: 0.9297, test_Accuracy: 0.9416\n",
      "Epoch: [ 0] [  398/  468] time: 401.5851, train_loss: 0.23457652, train_accuracy: 0.9453, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  399/  468] time: 402.5441, train_loss: 0.33389151, train_accuracy: 0.9531, test_Accuracy: 0.9425\n",
      "Epoch: [ 0] [  400/  468] time: 403.5741, train_loss: 0.46743590, train_accuracy: 0.9219, test_Accuracy: 0.9426\n",
      "Epoch: [ 0] [  401/  468] time: 404.5801, train_loss: 0.31693131, train_accuracy: 0.9219, test_Accuracy: 0.9434\n",
      "Epoch: [ 0] [  402/  468] time: 405.6891, train_loss: 0.30725640, train_accuracy: 0.9141, test_Accuracy: 0.9434\n",
      "Epoch: [ 0] [  403/  468] time: 406.7831, train_loss: 0.13531920, train_accuracy: 0.9766, test_Accuracy: 0.9435\n",
      "Epoch: [ 0] [  404/  468] time: 407.7411, train_loss: 0.23374067, train_accuracy: 0.9766, test_Accuracy: 0.9439\n",
      "Epoch: [ 0] [  405/  468] time: 408.6881, train_loss: 0.28593680, train_accuracy: 0.9219, test_Accuracy: 0.9437\n",
      "Epoch: [ 0] [  406/  468] time: 409.6901, train_loss: 0.26239327, train_accuracy: 0.9609, test_Accuracy: 0.9437\n",
      "Epoch: [ 0] [  407/  468] time: 410.7291, train_loss: 0.26555383, train_accuracy: 0.9844, test_Accuracy: 0.9442\n",
      "Epoch: [ 0] [  408/  468] time: 411.7991, train_loss: 0.35553625, train_accuracy: 0.9609, test_Accuracy: 0.9437\n",
      "Epoch: [ 0] [  409/  468] time: 412.7311, train_loss: 0.23996404, train_accuracy: 0.9688, test_Accuracy: 0.9436\n",
      "Epoch: [ 0] [  410/  468] time: 413.7711, train_loss: 0.34194446, train_accuracy: 0.9297, test_Accuracy: 0.9441\n",
      "Epoch: [ 0] [  411/  468] time: 414.7421, train_loss: 0.39696407, train_accuracy: 0.9141, test_Accuracy: 0.9449\n",
      "Epoch: [ 0] [  412/  468] time: 415.7511, train_loss: 0.41989553, train_accuracy: 0.8984, test_Accuracy: 0.9458\n",
      "Epoch: [ 0] [  413/  468] time: 417.1621, train_loss: 0.34824389, train_accuracy: 0.9453, test_Accuracy: 0.9451\n",
      "Epoch: [ 0] [  414/  468] time: 418.0941, train_loss: 0.32071126, train_accuracy: 0.9297, test_Accuracy: 0.9446\n",
      "Epoch: [ 0] [  415/  468] time: 419.0261, train_loss: 0.34376395, train_accuracy: 0.9453, test_Accuracy: 0.9445\n",
      "Epoch: [ 0] [  416/  468] time: 420.0591, train_loss: 0.40514183, train_accuracy: 0.9531, test_Accuracy: 0.9436\n",
      "Epoch: [ 0] [  417/  468] time: 421.0421, train_loss: 0.41974732, train_accuracy: 0.8906, test_Accuracy: 0.9435\n",
      "Epoch: [ 0] [  418/  468] time: 422.0671, train_loss: 0.41011536, train_accuracy: 0.9141, test_Accuracy: 0.9432\n",
      "Epoch: [ 0] [  419/  468] time: 423.1071, train_loss: 0.24801634, train_accuracy: 0.9688, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  420/  468] time: 424.1151, train_loss: 0.33844414, train_accuracy: 0.9375, test_Accuracy: 0.9419\n",
      "Epoch: [ 0] [  421/  468] time: 425.1261, train_loss: 0.31861225, train_accuracy: 0.9375, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  422/  468] time: 426.1131, train_loss: 0.34089193, train_accuracy: 0.9531, test_Accuracy: 0.9414\n",
      "Epoch: [ 0] [  423/  468] time: 427.1021, train_loss: 0.44501728, train_accuracy: 0.8984, test_Accuracy: 0.9420\n",
      "Epoch: [ 0] [  424/  468] time: 428.1041, train_loss: 0.25321484, train_accuracy: 0.9688, test_Accuracy: 0.9416\n",
      "Epoch: [ 0] [  425/  468] time: 429.2251, train_loss: 0.30599618, train_accuracy: 0.9297, test_Accuracy: 0.9422\n",
      "Epoch: [ 0] [  426/  468] time: 430.1501, train_loss: 0.28871635, train_accuracy: 0.9375, test_Accuracy: 0.9419\n",
      "Epoch: [ 0] [  427/  468] time: 431.1481, train_loss: 0.45770133, train_accuracy: 0.9219, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  428/  468] time: 432.1891, train_loss: 0.39615172, train_accuracy: 0.9375, test_Accuracy: 0.9422\n",
      "Epoch: [ 0] [  429/  468] time: 433.2131, train_loss: 0.44428241, train_accuracy: 0.9297, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  430/  468] time: 434.2411, train_loss: 0.30241305, train_accuracy: 0.9609, test_Accuracy: 0.9422\n",
      "Epoch: [ 0] [  431/  468] time: 435.2061, train_loss: 0.48563123, train_accuracy: 0.9062, test_Accuracy: 0.9428\n",
      "Epoch: [ 0] [  432/  468] time: 436.1531, train_loss: 0.35888878, train_accuracy: 0.9219, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  433/  468] time: 437.1521, train_loss: 0.28040662, train_accuracy: 0.9531, test_Accuracy: 0.9433\n",
      "Epoch: [ 0] [  434/  468] time: 438.1111, train_loss: 0.31500924, train_accuracy: 0.9453, test_Accuracy: 0.9428\n",
      "Epoch: [ 0] [  435/  468] time: 439.0751, train_loss: 0.33893859, train_accuracy: 0.9297, test_Accuracy: 0.9431\n",
      "Epoch: [ 0] [  436/  468] time: 440.0431, train_loss: 0.25150383, train_accuracy: 0.9219, test_Accuracy: 0.9433\n",
      "Epoch: [ 0] [  437/  468] time: 440.9961, train_loss: 0.27652290, train_accuracy: 0.9453, test_Accuracy: 0.9435\n",
      "Epoch: [ 0] [  438/  468] time: 442.4661, train_loss: 0.28483629, train_accuracy: 0.9297, test_Accuracy: 0.9429\n",
      "Epoch: [ 0] [  439/  468] time: 443.4521, train_loss: 0.31365895, train_accuracy: 0.9688, test_Accuracy: 0.9432\n",
      "Epoch: [ 0] [  440/  468] time: 444.4031, train_loss: 0.29844567, train_accuracy: 0.9375, test_Accuracy: 0.9430\n",
      "Epoch: [ 0] [  441/  468] time: 445.3551, train_loss: 0.18188301, train_accuracy: 0.9609, test_Accuracy: 0.9428\n",
      "Epoch: [ 0] [  442/  468] time: 446.2801, train_loss: 0.27612039, train_accuracy: 0.9375, test_Accuracy: 0.9427\n",
      "Epoch: [ 0] [  443/  468] time: 447.1981, train_loss: 0.29995054, train_accuracy: 0.9453, test_Accuracy: 0.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  444/  468] time: 448.1911, train_loss: 0.25590715, train_accuracy: 0.9375, test_Accuracy: 0.9437\n",
      "Epoch: [ 0] [  445/  468] time: 449.1281, train_loss: 0.29291844, train_accuracy: 0.9688, test_Accuracy: 0.9440\n",
      "Epoch: [ 0] [  446/  468] time: 450.0641, train_loss: 0.28541768, train_accuracy: 0.9297, test_Accuracy: 0.9438\n",
      "Epoch: [ 0] [  447/  468] time: 451.0031, train_loss: 0.19306521, train_accuracy: 0.9453, test_Accuracy: 0.9443\n",
      "Epoch: [ 0] [  448/  468] time: 451.9671, train_loss: 0.34481627, train_accuracy: 0.9531, test_Accuracy: 0.9445\n",
      "Epoch: [ 0] [  449/  468] time: 452.9171, train_loss: 0.26042220, train_accuracy: 0.9453, test_Accuracy: 0.9449\n",
      "Epoch: [ 0] [  450/  468] time: 453.8491, train_loss: 0.23925141, train_accuracy: 0.9609, test_Accuracy: 0.9447\n",
      "Epoch: [ 0] [  451/  468] time: 454.8011, train_loss: 0.32224321, train_accuracy: 0.9453, test_Accuracy: 0.9445\n",
      "Epoch: [ 0] [  452/  468] time: 455.7111, train_loss: 0.34509569, train_accuracy: 0.9297, test_Accuracy: 0.9442\n",
      "Epoch: [ 0] [  453/  468] time: 456.6381, train_loss: 0.32655239, train_accuracy: 0.9219, test_Accuracy: 0.9441\n",
      "Epoch: [ 0] [  454/  468] time: 457.5511, train_loss: 0.31507003, train_accuracy: 0.9297, test_Accuracy: 0.9442\n",
      "Epoch: [ 0] [  455/  468] time: 458.4761, train_loss: 0.23535916, train_accuracy: 0.9688, test_Accuracy: 0.9431\n",
      "Epoch: [ 0] [  456/  468] time: 459.3841, train_loss: 0.28793699, train_accuracy: 0.9375, test_Accuracy: 0.9433\n",
      "Epoch: [ 0] [  457/  468] time: 460.2991, train_loss: 0.17935273, train_accuracy: 0.9922, test_Accuracy: 0.9428\n",
      "Epoch: [ 0] [  458/  468] time: 461.2331, train_loss: 0.29223010, train_accuracy: 0.9531, test_Accuracy: 0.9427\n",
      "Epoch: [ 0] [  459/  468] time: 462.1601, train_loss: 0.33600259, train_accuracy: 0.9531, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  460/  468] time: 463.1011, train_loss: 0.20898008, train_accuracy: 0.9219, test_Accuracy: 0.9425\n",
      "Epoch: [ 0] [  461/  468] time: 464.0271, train_loss: 0.37288094, train_accuracy: 0.9375, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  462/  468] time: 464.9711, train_loss: 0.23898919, train_accuracy: 0.9453, test_Accuracy: 0.9429\n",
      "Epoch: [ 0] [  463/  468] time: 465.9451, train_loss: 0.32607615, train_accuracy: 0.9297, test_Accuracy: 0.9432\n",
      "Epoch: [ 0] [  464/  468] time: 466.9021, train_loss: 0.41804540, train_accuracy: 0.9375, test_Accuracy: 0.9441\n",
      "Epoch: [ 0] [  465/  468] time: 467.8451, train_loss: 0.26610652, train_accuracy: 0.9844, test_Accuracy: 0.9442\n",
      "Epoch: [ 0] [  466/  468] time: 468.7731, train_loss: 0.31936187, train_accuracy: 0.9609, test_Accuracy: 0.9444\n",
      "Epoch: [ 0] [  467/  468] time: 469.6951, train_loss: 0.30050731, train_accuracy: 0.9531, test_Accuracy: 0.9447\n"
     ]
    }
   ],
   "source": [
    "if train_flag :\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
    "\n",
    "    # create writer for tensorboard\n",
    "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
    "    start_time = time()\n",
    "\n",
    "    # restore check-point if it exits\n",
    "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
    "\n",
    "    if could_load:\n",
    "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
    "        counter = checkpoint_counter        \n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        start_iteration = 0\n",
    "        counter = 0\n",
    "        print(\" [!] Load failed...\")\n",
    "    \n",
    "    # train phase\n",
    "    with summary_writer.as_default():  # for tensorboard\n",
    "        for epoch in range(start_epoch, training_epochs):\n",
    "            for idx, (train_input, train_label) in enumerate(train_dataset):            \n",
    "                grads = grad(network, train_input, train_label)\n",
    "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.trainable_variables)) # 여기도 variables 대신 trainable_variables로 변경\n",
    "\n",
    "                train_loss = loss_fn(network, train_input, train_label)\n",
    "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
    "                \n",
    "                for test_input, test_label in test_dataset:                \n",
    "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
    "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
    "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
    "\n",
    "                print(\n",
    "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
    "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
    "                       test_accuracy))\n",
    "                counter += 1                \n",
    "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
    "        \n",
    "# test phase      \n",
    "else :\n",
    "    _, _ = load(network, checkpoint_dir)\n",
    "    for test_input, test_label in test_dataset:    \n",
    "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 결론\n",
    "> Batch Normalization 기법을 쓰면, 좀 더 높은 accuracy의 모델을 만들 수 있다.\n",
    "\n",
    "### Using Batch Normalization\n",
    "- Test Accuracy : 94.47%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
